{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recommendation System - Personal Library Analysis\n",
    "\n",
    "This notebook processes personal Spotify library data and builds a mood-based music recommendation system.\n",
    "\n",
    "## Overview\n",
    "- Personal library: 13,079 songs\n",
    "- Matching with global dataset: 478 songs matched\n",
    "- Clustering: Hierarchical mood-based clusters\n",
    "- Recommendation: Cosine similarity-based with proportional subcluster allocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "global_df = pd.read_csv('dataset_cleaned.csv')\n",
    "global_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Your Library JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file\n",
    "with open('yourlibrary.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert the tracks array to a DataFrame\n",
    "personal_df_raw = pd.DataFrame(data['tracks'])\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(f\"Shape: {personal_df_raw.shape}\")\n",
    "print(f\"\\nColumns: {personal_df_raw.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "personal_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace and convert to lowercase for artist, album, and track columns\n",
    "personal_df_raw['artist'] = personal_df_raw['artist'].str.strip().str.lower()\n",
    "personal_df_raw['album'] = personal_df_raw['album'].str.strip().str.lower()\n",
    "personal_df_raw['track'] = personal_df_raw['track'].str.strip().str.lower()\n",
    "print(len(personal_df_raw))\n",
    "print(\"Cleaned columns - first few rows:\")\n",
    "\n",
    "# Drop duplicates in eprsonal data:\n",
    "personal_df_raw = personal_df_raw.drop_duplicates(\n",
    "    subset=['track', 'artist'], keep='first')\n",
    "print(len(personal_df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset CSV\n",
    "global_df = pd.read_csv('dataset_cleaned.csv')\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(f\"Shape: {global_df.shape}\")\n",
    "print(f\"\\nColumns: {global_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "global_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge personal_df_raw and global_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join personal_df_raw and global_df based on matching artist, and track\n",
    "# We need to check if personal_df_raw['artist'] matches ANY of the artist columns in global_df\n",
    "# Merge personal_df_raw and global_df where personal_df_raw.artist matches global_df.artist_1 AND personal_df_raw.track matches global_df.track_name\n",
    "personal_df = personal_df_raw.merge(\n",
    "    global_df,\n",
    "    left_on=['artist', 'track'],\n",
    "    right_on=['artist_1', 'track_name'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Original personal_df_raw shape: {personal_df_raw.shape}\")\n",
    "print(f\"Original global_df shape: {global_df.shape}\")\n",
    "print(f\"Merged dataframe shape: {personal_df.shape}\")\n",
    "print(f\"\\nNumber of songs from your library that matched: {len(personal_df)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "personal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged dataframe to CSV\n",
    "personal_df.to_csv('personal_df.csv', index=False)\n",
    "print(\"Saved personal_df to personal_df.csv\")\n",
    "personal_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Track Features and Metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_df.drop(columns=['artist', 'album', 'track', 'uri'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata col\n",
    "metadata_cols = ['track_id', 'track_name', 'artist_1', 'artist_2',\n",
    "                 'artist_3', 'album_name',  'duration_ms', 'popularity', 'explicit']\n",
    "# Audio feature cols\n",
    "audio_feature_cols = ['danceability', 'energy', 'loudness_scaled', 'mode', 'speechiness',\n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo_scaled']\n",
    "\n",
    "# Split global data into audio_features and metadata\n",
    "global_metadata_df = global_df[metadata_cols]\n",
    "global_feature_value_df = global_df[audio_feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Sample 5000 rows from global_feature_value_df\n",
    "# df_sample = global_feature_value_df.sample(n=5000, random_state=42)\n",
    "\n",
    "# # Create linkage matrix (no scaling needed - data already scaled)\n",
    "# linkage_matrix = linkage(df_sample, method='ward')\n",
    "\n",
    "# # Plot dendrogram\n",
    "# plt.figure(figsize=(15, 8))\n",
    "# dendrogram(linkage_matrix,\n",
    "#            truncate_mode='lastp',\n",
    "#            p=40,\n",
    "#            leaf_rotation=90,\n",
    "#            leaf_font_size=10,\n",
    "#            show_contracted=True)\n",
    "# plt.title('Hierarchical Clustering Dendrogram (5000 samples, Ward Linkage)', fontsize=16)\n",
    "# plt.xlabel('Cluster Size', fontsize=12)\n",
    "# plt.ylabel('Distance', fontsize=12)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Sample data (use same sample as dendrogram)\n",
    "# df_sample = global_feature_value_df.sample(n=5000, random_state=42)\n",
    "\n",
    "# # Create clustermap\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.clustermap(df_sample,\n",
    "#                method='ward',\n",
    "#                cmap='viridis',\n",
    "#                figsize=(12, 10),\n",
    "#                cbar_kws={'label': 'Feature Value'})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import silhouette_score\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# silhouette_values_hier = []\n",
    "\n",
    "# for k in range(2, 10):\n",
    "#     agg_temp = AgglomerativeClustering(n_clusters=k)\n",
    "#     agg_temp.fit(df_sample)\n",
    "#     silhouette = silhouette_score(df_sample, agg_temp.labels_)\n",
    "#     silhouette_values_hier.append(silhouette)\n",
    "\n",
    "# silhouette_series_hier = pd.Series(silhouette_values_hier, index=range(2, 10))\n",
    "\n",
    "# silhouette_series_hier.plot(marker='o')\n",
    "# plt.xlabel(\"Number of Clusters (k)\")\n",
    "# plt.ylabel(\"Silhouette Score\")\n",
    "# plt.title(\"Hierarchical Clustering: Number of Clusters vs. Silhouette Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ELBOW METHOD - Finding Optimal K using Inertia\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use entire dataset\n",
    "print(f\"Using entire dataset: {len(global_feature_value_df)} tracks\")\n",
    "\n",
    "# Calculate inertia for different values of K\n",
    "inertias = []\n",
    "K_range = range(2, 15)\n",
    "\n",
    "print(\"\\nCalculating inertia for different K values...\")\n",
    "for k in K_range:\n",
    "    print(f\"  Computing K={k}...\")\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(global_feature_value_df)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    print(f\"    K={k}: Inertia={kmeans.inertia_:.2f}\")\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(K_range, inertias, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)', fontsize=12)\n",
    "plt.ylabel('Inertia (Within-Cluster Sum of Squares)', fontsize=12)\n",
    "plt.title(\n",
    "    f'Elbow Method - Optimal K Selection ({len(global_feature_value_df)} tracks)', fontsize=16)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(K_range)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLook for the 'elbow' point where inertia starts to decrease more slowly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# K-MEANS CLUSTERING: Cluster entire dataset into 6 clusters\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Clustering entire dataset into 6 clusters using K-Means...\")\n",
    "\n",
    "# Perform K-Means clustering on global_feature_value_df\n",
    "kmeans = KMeans(n_clusters=6, random_state=42, n_init=200, max_iter=600)\n",
    "cluster_labels = kmeans.fit_predict(global_feature_value_df)\n",
    "\n",
    "print(\n",
    "    f\"Clustering complete! Clustered {len(cluster_labels)} tracks into 6 clusters.\")\n",
    "print(\"\\nCluster Sizes:\")\n",
    "unique, counts = np.unique(cluster_labels, return_counts=True)\n",
    "for cluster_id, count in zip(unique, counts):\n",
    "    print(f\"  Cluster {cluster_id}: {count} tracks\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Calculate and save average feature values for each cluster\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Calculating average feature values for each cluster...\")\n",
    "\n",
    "# Create a temporary dataframe with features and cluster labels\n",
    "feature_cluster_df = global_feature_value_df.copy()\n",
    "feature_cluster_df['cluster'] = cluster_labels\n",
    "\n",
    "# Calculate mean feature values for each cluster\n",
    "cluster_profiles = feature_cluster_df.groupby(\n",
    "    'cluster')[audio_feature_cols].mean()\n",
    "\n",
    "# Add cluster size to the profiles\n",
    "cluster_profiles['cluster_size'] = feature_cluster_df.groupby('cluster').size()\n",
    "\n",
    "print(\"\\nCluster Profiles (Average Feature Values):\")\n",
    "print(cluster_profiles.round(3))\n",
    "\n",
    "# Save cluster profiles to CSV\n",
    "cluster_profiles.to_csv('kmeans_cluster_profiles.csv')\n",
    "print(\"\\n\u2713 Saved cluster profiles to 'kmeans_cluster_profiles.csv'\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Add cluster labels to dataset_cleaned and save\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Adding cluster labels to dataset_cleaned.csv...\")\n",
    "\n",
    "# Read the original dataset_cleaned.csv\n",
    "dataset_cleaned = pd.read_csv('dataset_cleaned.csv')\n",
    "\n",
    "# Add the main cluster column\n",
    "dataset_cleaned['main_cluster'] = cluster_labels\n",
    "\n",
    "# Display sample with cluster labels\n",
    "print(\"\\nSample of data with cluster labels:\")\n",
    "print(dataset_cleaned[['track_name', 'artist_1', 'main_cluster',\n",
    "      'danceability', 'energy', 'valence']].head(10))\n",
    "\n",
    "# Save the updated dataset with cluster labels\n",
    "dataset_cleaned.to_csv('dataset_cleaned_with_kmeans_clusters.csv', index=False)\n",
    "print(\"\\n\u2713 Saved dataset with cluster labels to 'dataset_cleaned_with_kmeans_clusters.csv'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"K-MEANS CLUSTERING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total tracks clustered: {len(cluster_labels)}\")\n",
    "print(f\"Number of clusters: 6\")\n",
    "print(f\"Inertia (within-cluster sum of squares): {kmeans.inertia_:.2f}\")\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  1. kmeans_cluster_profiles.csv - Average feature values for each cluster\")\n",
    "print(f\"  2. dataset_cleaned_with_kmeans_clusters.csv - Original dataset with 'main_cluster' column (0-5) added\")\n",
    "\n",
    "#   Cluster 0: 5223 tracks\n",
    "#   Cluster 1: 14896 tracks\n",
    "#   Cluster 2: 25335 tracks\n",
    "#   Cluster 3: 22103 tracks\n",
    "#   Cluster 4: 5734 tracks\n",
    "#   Cluster 5: 5206 tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the final mood labels for each cluster, along with the reasoning behind each one.\n",
    "\n",
    "---\n",
    "\n",
    "## ## **Cluster Summary Table**\n",
    "\n",
    "| Cluster | Mood Label                |\n",
    "| ------- | ------------------------- |\n",
    "| **0**   | Moody Energetic           |\n",
    "| **1**   | Sad / Reflective          |\n",
    "| **2**   | Happy / Energetic         |\n",
    "| **3**   | Warm / Feel-Good          |\n",
    "| **4**   | Intense / Driven          |\n",
    "| **5**   | Melancholy / Peaceful Sad |\n",
    "\n",
    "---\n",
    "\n",
    "# \ud83c\udfaf **Cluster Explanations**\n",
    "\n",
    "---\n",
    "\n",
    "## **Cluster 0 \u2014 \u201cMoody Energetic\u201d**\n",
    "\n",
    "> **Reasoning:**\n",
    ">\n",
    "> - Medium\u2013high energy\n",
    "> - Moderate danceability\n",
    "> - Low valence \u2192 emotionally darker\n",
    "> - Low acousticness \u2192 tense / not warm\n",
    ">\n",
    "> **Mood:** Moody Energetic\n",
    "\n",
    "---\n",
    "\n",
    "## **Cluster 1 \u2014 \u201cSad / Reflective\u201d**\n",
    "\n",
    "> **Reasoning:**\n",
    ">\n",
    "> - Low energy\n",
    "> - High acousticness \u2192 soft, intimate\n",
    "> - Lower valence \u2192 emotional / wistful\n",
    "> - Slightly higher speechiness \u2192 expressive\n",
    ">\n",
    "> **Mood:** Sad / Reflective\n",
    "\n",
    "---\n",
    "\n",
    "## **Cluster 2 \u2014 \u201cHappy / Energetic\u201d**\n",
    "\n",
    "> **Reasoning:**\n",
    ">\n",
    "> - Highest energy of all clusters\n",
    "> - High danceability\n",
    "> - Highest valence \u2192 cheerful / bright\n",
    "> - Low acousticness \u2192 lively\n",
    ">\n",
    "> **Mood:** Happy / Energetic\n",
    "\n",
    "---\n",
    "\n",
    "## **Cluster 3 \u2014 \u201cWarm / Feel-Good\u201d**\n",
    "\n",
    "> **Reasoning:**\n",
    ">\n",
    "> - Medium\u2013high energy\n",
    "> - Good danceability\n",
    "> - Moderately positive valence\n",
    "> - Moderate acousticness \u2192 warmth\n",
    ">\n",
    "> **Mood:** Warm / Feel-Good\n",
    "\n",
    "---\n",
    "\n",
    "## **Cluster 4 \u2014 \u201cIntense / Driven\u201d**\n",
    "\n",
    "> **Reasoning:**\n",
    ">\n",
    "> - High energy\n",
    "> - Low valence \u2192 serious, not cheerful\n",
    "> - Low acousticness \u2192 sharper / aggressive tone\n",
    "> - Very high instrumentalness \u2192 focused\n",
    ">\n",
    "> **Mood:** Intense / Driven\n",
    "\n",
    "---\n",
    "\n",
    "## **Cluster 5 \u2014 \u201cMelancholy / Peaceful Sad\u201d**\n",
    "\n",
    "> **Reasoning:**\n",
    ">\n",
    "> - Lowest energy\n",
    "> - Highest acousticness\n",
    "> - Lowest valence \u2192 emotional heaviness\n",
    "> - High instrumentalness \u2192 quiet, drifting\n",
    ">\n",
    "> **Mood:** Melancholy / Peaceful Sad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mood label dictionary\n",
    "mood_labels = {\n",
    "    0: \"Moody Energetic\",\n",
    "    1: \"Sad / Reflective\",\n",
    "    2: \"Happy / Energetic\",\n",
    "    3: \"Warm / Feel-Good\",\n",
    "    4: \"Intense / Driven\",\n",
    "    5: \"Melancholy / Peaceful Sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subclusters\n",
    "\n",
    "We would like to further split each cluster into subclusters according to cluster size\n",
    "The logic is <10000 songs, dont split. 10000<=songs in cluster <20000 we split into 2, and above 20000 we split into 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CREATE SUBCLUSTERS: Split clusters based on size\n",
    "# Logic: <10000 = no split, 10000-20000 = 2 subclusters, >20000 = 3 subclusters\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Creating subclusters based on main cluster sizes...\")\n",
    "print(\"\\nSubclustering Logic:\")\n",
    "print(\"  < 10,000 songs: No split (subcluster = 0)\")\n",
    "print(\"  10,000 - 20,000 songs: Split into 2 subclusters\")\n",
    "print(\"  > 20,000 songs: Split into 3 subclusters\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Read the dataset with main clusters\n",
    "dataset_with_clusters = pd.read_csv('dataset_cleaned_with_kmeans_clusters.csv')\n",
    "\n",
    "# Initialize subcluster labels array\n",
    "subcluster_labels = np.zeros(len(dataset_with_clusters), dtype=int)\n",
    "\n",
    "# Process each main cluster\n",
    "for cluster_id in range(6):\n",
    "    # Get data for this cluster\n",
    "    cluster_mask = dataset_with_clusters['main_cluster'] == cluster_id\n",
    "    cluster_indices = np.where(cluster_mask)[0]\n",
    "    cluster_size = len(cluster_indices)\n",
    "\n",
    "    # Get feature data for this cluster\n",
    "    cluster_features = global_feature_value_df.iloc[cluster_indices]\n",
    "\n",
    "    # Determine number of subclusters based on size\n",
    "    if cluster_size < 10000:\n",
    "        n_subclusters = 1  # No split\n",
    "        print(\n",
    "            f\"Cluster {cluster_id}: {cluster_size:,} tracks -> No split (too small)\")\n",
    "    elif cluster_size < 20000:\n",
    "        n_subclusters = 2\n",
    "        print(\n",
    "            f\"Cluster {cluster_id}: {cluster_size:,} tracks -> 2 subclusters\")\n",
    "    else:\n",
    "        n_subclusters = 3\n",
    "        print(\n",
    "            f\"Cluster {cluster_id}: {cluster_size:,} tracks -> 3 subclusters\")\n",
    "\n",
    "    # Perform subclustering\n",
    "    if n_subclusters == 1:\n",
    "        # No split - all songs get subcluster 0\n",
    "        sub_labels = np.zeros(cluster_size, dtype=int)\n",
    "    else:\n",
    "        # Use K-Means to create subclusters\n",
    "        kmeans_sub = KMeans(n_clusters=n_subclusters,\n",
    "                            random_state=42, n_init=10)\n",
    "        sub_labels = kmeans_sub.fit_predict(cluster_features)\n",
    "\n",
    "    # Assign subcluster labels\n",
    "    subcluster_labels[cluster_indices] = sub_labels\n",
    "\n",
    "# Add subcluster column to dataset\n",
    "dataset_with_clusters['subcluster'] = subcluster_labels\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Subcluster Summary:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for cluster_id in range(6):\n",
    "    cluster_data = dataset_with_clusters[dataset_with_clusters['main_cluster'] == cluster_id]\n",
    "    n_subclusters = cluster_data['subcluster'].nunique()\n",
    "\n",
    "    print(f\"\\nMain Cluster {cluster_id} ({len(cluster_data):,} tracks):\")\n",
    "    print(f\"  Number of subclusters: {n_subclusters}\")\n",
    "\n",
    "    # Show subcluster sizes\n",
    "    subcluster_counts = cluster_data['subcluster'].value_counts().sort_index()\n",
    "    for sub_id, count in subcluster_counts.items():\n",
    "        print(f\"    Subcluster {sub_id}: {count:,} tracks\")\n",
    "\n",
    "# Calculate average features for each subcluster within each main cluster\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Subcluster Profiles:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "subcluster_profiles_list = []\n",
    "\n",
    "for cluster_id in range(6):\n",
    "    cluster_data = dataset_with_clusters[dataset_with_clusters['main_cluster'] == cluster_id]\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Main Cluster {cluster_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    for sub_id in sorted(cluster_data['subcluster'].unique()):\n",
    "        sub_mask = cluster_data['subcluster'] == sub_id\n",
    "        sub_indices = cluster_data[sub_mask].index\n",
    "        sub_features = global_feature_value_df.iloc[sub_indices]\n",
    "\n",
    "        # Calculate mean features\n",
    "        sub_profile = sub_features.mean()\n",
    "        sub_profile['main_cluster'] = cluster_id\n",
    "        sub_profile['subcluster'] = sub_id\n",
    "        sub_profile['size'] = len(sub_indices)\n",
    "\n",
    "        subcluster_profiles_list.append(sub_profile)\n",
    "\n",
    "        print(\n",
    "            f\"\\n  Subcluster {cluster_id}.{sub_id} ({len(sub_indices):,} tracks):\")\n",
    "        print(f\"    Danceability: {sub_profile['danceability']:.3f}\")\n",
    "        print(f\"    Energy: {sub_profile['energy']:.3f}\")\n",
    "        print(f\"    Valence: {sub_profile['valence']:.3f}\")\n",
    "        print(f\"    Acousticness: {sub_profile['acousticness']:.3f}\")\n",
    "        print(f\"    Instrumentalness: {sub_profile['instrumentalness']:.3f}\")\n",
    "\n",
    "# Create DataFrame of subcluster profiles\n",
    "subcluster_profiles_df = pd.DataFrame(subcluster_profiles_list)\n",
    "\n",
    "# Save subcluster profiles to CSV\n",
    "subcluster_profiles_df.to_csv('kmeans_subcluster_profiles.csv', index=False)\n",
    "print(\"\\n\u2713 Saved subcluster profiles to 'kmeans_subcluster_profiles.csv'\")\n",
    "\n",
    "# Save the dataset with both main clusters and subclusters\n",
    "dataset_with_clusters.to_csv(\n",
    "    'dataset_cleaned_with_kmeans_subclusters.csv', index=False)\n",
    "print(\"\u2713 Saved dataset with subclusters to 'dataset_cleaned_with_kmeans_subclusters.csv'\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample of data with cluster and subcluster labels:\")\n",
    "print(\"=\"*80)\n",
    "print(dataset_with_clusters[['track_name', 'artist_1', 'main_cluster',\n",
    "      'subcluster', 'danceability', 'energy', 'valence']].head(15))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUBCLUSTERING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  1. kmeans_subcluster_profiles.csv - Average features for each subcluster\")\n",
    "print(f\"  2. dataset_cleaned_with_kmeans_subclusters.csv - Dataset with 'main_cluster' and 'subcluster' columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gradio as gr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# --- Your backend logic (kept exactly the same as requested) ---\n",
    "global_df = pd.read_csv('dataset_cleaned_with_kmeans_subclusters.csv')\n",
    "personal_df_raw = pd.read_csv('personal_df.csv')\n",
    "\n",
    "personal_df = personal_df_raw.merge(\n",
    "    global_df[['track_id', 'main_cluster', 'subcluster']],\n",
    "    on='track_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "audio_feature_cols = ['danceability', 'energy', 'loudness_scaled', 'mode', 'speechiness',\n",
    "                      'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo_scaled']\n",
    "\n",
    "CLUSTER_MOODS = {\n",
    "    0: \"Moody Energetic\",\n",
    "    1: \"Sad / Reflective\",\n",
    "    2: \"Happy / Energetic\",\n",
    "    3: \"Warm / Feel-Good\",\n",
    "    4: \"Intense / Driven\",\n",
    "    5: \"Melancholy / Peaceful Sad\"\n",
    "}\n",
    "\n",
    "\n",
    "def generate_playlist(mood, n_songs):\n",
    "    main_cluster = list(CLUSTER_MOODS.keys())[\n",
    "        list(CLUSTER_MOODS.values()).index(mood)]\n",
    "    user_songs_in_cluster = personal_df[personal_df['main_cluster']\n",
    "                                        == main_cluster]\n",
    "\n",
    "    if user_songs_in_cluster.empty:\n",
    "        return pd.DataFrame({'Message': [f\"You don't have any songs in the '{mood}' category.\"]})\n",
    "\n",
    "    subcluster_counts = user_songs_in_cluster['subcluster'].value_counts()\n",
    "    total_user_songs = len(user_songs_in_cluster)\n",
    "\n",
    "    subcluster_allocations = {}\n",
    "    for subcluster, count in subcluster_counts.items():\n",
    "        ratio = count / total_user_songs\n",
    "        subcluster_allocations[subcluster] = int(np.round(n_songs * ratio))\n",
    "\n",
    "    diff = n_songs - sum(subcluster_allocations.values())\n",
    "    if diff > 0:\n",
    "        if subcluster_allocations:\n",
    "            max_subcluster = max(subcluster_allocations,\n",
    "                                 key=subcluster_allocations.get)\n",
    "            subcluster_allocations[max_subcluster] += diff\n",
    "\n",
    "    all_recommendations = []\n",
    "    personal_features = personal_df[audio_feature_cols].mean(\n",
    "    ).values.reshape(1, -1)\n",
    "\n",
    "    for subcluster, num_songs_needed in subcluster_allocations.items():\n",
    "        if num_songs_needed <= 0:\n",
    "            continue\n",
    "\n",
    "        candidates = global_df[\n",
    "            (global_df['main_cluster'] == main_cluster) &\n",
    "            (global_df['subcluster'] == subcluster)\n",
    "        ].copy()\n",
    "\n",
    "        candidates = candidates[~candidates['track_id'].isin(\n",
    "            personal_df['track_id'])]\n",
    "\n",
    "        if candidates.empty:\n",
    "            continue\n",
    "\n",
    "        candidate_features = candidates[audio_feature_cols].values\n",
    "\n",
    "        if personal_features.size == 0 or candidate_features.size == 0:\n",
    "            continue\n",
    "\n",
    "        similarities = cosine_similarity(\n",
    "            personal_features, candidate_features)[0]\n",
    "\n",
    "        candidates['similarity'] = similarities\n",
    "        recs = candidates.nlargest(num_songs_needed, 'similarity')\n",
    "        all_recommendations.append(recs)\n",
    "\n",
    "    if not all_recommendations:\n",
    "        return pd.DataFrame({'Message': [f\"Could not find new songs matching your '{mood}' profile.\"]})\n",
    "\n",
    "    final_playlist = pd.concat(all_recommendations)\n",
    "    final_playlist['similarity'] = final_playlist['similarity'].apply(\n",
    "        lambda x: f\"{x*100:.0f}%\")\n",
    "\n",
    "    return final_playlist[['track_name', 'artist_1', 'similarity']]\n",
    "\n",
    "# --- Gradio Interface with Spotify-themed CSS ---\n",
    "\n",
    "\n",
    "custom_css = \"\"\"\n",
    "/* Overall Body Background - Pure Black */\n",
    "body {\n",
    "    background-color: #000000 !important; \n",
    "    font-family: 'Circular', 'Helvetica Neue', Helvetica, Arial, sans-serif !important;\n",
    "}\n",
    "\n",
    "/* Main Gradio Container - Dark Grey like Spotify's main areas */\n",
    ".gradio-container {\n",
    "    background-color: #121212 !important; \n",
    "    color: #FFFFFF !important;\n",
    "    border-radius: 8px !important;\n",
    "    padding: 20px !important; /* Internal padding */\n",
    "    box-shadow: 0 4px 12px rgba(0, 0, 0, 0.5) !important; /* Subtle shadow */\n",
    "    max-width: 900px; /* Constrain width for a more app-like feel */\n",
    "    margin: 30px auto !important; /* Center on page */\n",
    "}\n",
    "\n",
    "/* Headings - White for main, lighter grey for sub-headings */\n",
    "h1, h2, h3, .gr-markdown {\n",
    "    color: #FFFFFF !important;\n",
    "    text-align: left !important;\n",
    "    padding-left: 0 !important;\n",
    "    margin-bottom: 0.5em !important;\n",
    "}\n",
    "\n",
    "/* Main Spotify-like Title */\n",
    "h1 {\n",
    "    font-size: 2.2em !important;\n",
    "    font-weight: bold !important;\n",
    "    color: #1DB954 !important; /* Spotify Green for the main title */\n",
    "    margin-bottom: 5px !important;\n",
    "}\n",
    "\n",
    "/* Subtitle */\n",
    ".gr-markdown h3 {\n",
    "    color: #B3B3B3 !important; /* Lighter grey for descriptive text */\n",
    "    font-size: 1.1em !important;\n",
    "    font-weight: normal !important;\n",
    "    margin-top: 0 !important;\n",
    "}\n",
    "\n",
    "/* Labels for inputs */\n",
    "label {\n",
    "    color: #B3B3B3 !important; \n",
    "    font-weight: 500 !important;\n",
    "}\n",
    "\n",
    "/* Input Backgrounds (Dropdown, Slider background) */\n",
    ".gr-dropdown, .gr-slider {\n",
    "    background-color: #282828 !important; /* Darker than container, lighter than black */\n",
    "    border-color: #404040 !important;\n",
    "    color: #FFFFFF !important;\n",
    "    border-radius: 4px !important;\n",
    "}\n",
    "\n",
    "/* Text inside inputs */\n",
    ".gr-text-input, .gr-dropdown-item {\n",
    "    color: #FFFFFF !important;\n",
    "}\n",
    "\n",
    "/* Slider Fill - Spotify Green */\n",
    ".gr-slider-fill {\n",
    "    background-color: #1DB954 !important;\n",
    "}\n",
    "\n",
    "/* Primary Button (Generate Playlist) - Spotify Green */\n",
    ".gr-button-primary {\n",
    "    background-color: #1DB954 !important;\n",
    "    color: #000000 !important; /* Black text on green button */\n",
    "    font-weight: bold !important;\n",
    "    border-radius: 500px !important; /* Pill shape */\n",
    "    padding: 12px 32px !important;\n",
    "    transition: background-color 0.2s ease, transform 0.2s ease;\n",
    "    border: none !important;\n",
    "    margin-top: 20px !important; /* Spacing */\n",
    "}\n",
    "\n",
    ".gr-button-primary:hover {\n",
    "    background-color: #1ED760 !important; /* Slightly lighter green on hover */\n",
    "    transform: scale(1.02);\n",
    "}\n",
    "\n",
    "/* Dataframe (Playlist Output) */\n",
    ".gr-dataframe {\n",
    "    background-color: #181818 !important; /* Match input panel background */\n",
    "    border-radius: 8px !important;\n",
    "    border: none !important;\n",
    "    margin-top: 30px !important; /* Spacing */\n",
    "}\n",
    "\n",
    "/* Table Header */\n",
    ".gr-dataframe th {\n",
    "    background-color: #000000 !important; /* Black header row */\n",
    "    color: #B3B3B3 !important; \n",
    "    font-weight: 400 !important;\n",
    "    text-transform: uppercase !important;\n",
    "    text-align: left !important;\n",
    "    padding: 12px 15px !important;\n",
    "    border-bottom: 1px solid #404040 !important;\n",
    "}\n",
    "\n",
    "/* Table Body Cells */\n",
    ".gr-dataframe td {\n",
    "    color: #FFFFFF !important;\n",
    "    border-color: #303030 !important; /* Subtle separator lines */\n",
    "    padding: 10px 15px !important;\n",
    "}\n",
    "\n",
    "/* Alternating row color and hover effect */\n",
    ".gr-dataframe tr:nth-child(even) {\n",
    "    background-color: #1a1a1a !important; /* Very dark grey for even rows */\n",
    "}\n",
    ".gr-dataframe tr:hover {\n",
    "    background-color: #282828 !important; /* Lighter dark grey on hover */\n",
    "}\n",
    "\n",
    "/* Hide the default Gradio footer */\n",
    ".gradio-footer {\n",
    "    display: none !important;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(title=\"Spotify Mood Recommender\") as demo:\n",
    "    demo.css = custom_css  # Apply the custom CSS here!\n",
    "\n",
    "    # Title and Subtitle\n",
    "    gr.Markdown(\"# \ud83c\udfb6 Spotify Mood Recommender\")\n",
    "    gr.Markdown(\"### Discover your next favorite songs based on your vibe\")\n",
    "\n",
    "    with gr.Row():\n",
    "        mood = gr.Dropdown(\n",
    "            choices=list(CLUSTER_MOODS.values()),\n",
    "            label=\"Select Your Mood\",\n",
    "            value=\"Happy / Energetic\",\n",
    "            container=False  # Prevent extra Gradio container around dropdown\n",
    "        )\n",
    "        n_songs = gr.Slider(\n",
    "            minimum=5,\n",
    "            maximum=50,\n",
    "            value=20,\n",
    "            step=1,\n",
    "            label=\"Number of Songs\",\n",
    "            container=False  # Prevent extra Gradio container around slider\n",
    "        )\n",
    "\n",
    "    btn = gr.Button(\"Generate Playlist\", variant=\"primary\")\n",
    "\n",
    "    output = gr.Dataframe(\n",
    "        label=\"Your Personalized Playlist\",\n",
    "        headers=[\"TRACK NAME\", \"ARTIST\", \"SIMILARITY\"],\n",
    "        interactive=False\n",
    "    )\n",
    "\n",
    "    btn.click(generate_playlist, inputs=[mood, n_songs], outputs=output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-SNE Visualization of Clusters\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# T-SNE VISUALIZATION - 2D Projection of Clusters\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Ensure inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the clustered dataset\n",
    "dataset_with_clusters = pd.read_csv('dataset_cleaned_with_kmeans_subclusters.csv')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Apply T-SNE to reduce to 2D\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    "    perplexity=30,\n",
    "    max_iter=1000,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Use the audio features for T-SNE\n",
    "features_2d = tsne.fit_transform(global_feature_value_df)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"T-SNE completed in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Create the visualization with 3 plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(28, 8))\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 1: Main Clusters Only\n",
    "# ============================================================================\n",
    "scatter1 = axes[0].scatter(\n",
    "    features_2d[:, 0],\n",
    "    features_2d[:, 1],\n",
    "    c=dataset_with_clusters['main_cluster'],\n",
    "    cmap='tab10',\n",
    "    alpha=0.6,\n",
    "    s=20,\n",
    "    edgecolors='none'\n",
    ")\n",
    "\n",
    "axes[0].set_title('Main Clusters (K=6)', fontsize=16, fontweight='bold')\n",
    "axes[0].set_xlabel('T-SNE Component 1', fontsize=12)\n",
    "axes[0].set_ylabel('T-SNE Component 2', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "cbar1 = plt.colorbar(scatter1, ax=axes[0])\n",
    "cbar1.set_label('Main Cluster', fontsize=12)\n",
    "\n",
    "# Add cluster labels with mood names\n",
    "for cluster_id in range(6):\n",
    "    cluster_mask = dataset_with_clusters['main_cluster'] == cluster_id\n",
    "    cluster_center = features_2d[cluster_mask].mean(axis=0)\n",
    "    mood_name = mood_labels[cluster_id]\n",
    "    \n",
    "    axes[0].annotate(\n",
    "        f'{cluster_id}\\n{mood_name}',\n",
    "        xy=cluster_center,\n",
    "        fontsize=9,\n",
    "        fontweight='bold',\n",
    "        color='white',\n",
    "        ha='center',\n",
    "        va='center',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', facecolor='black', alpha=0.7, edgecolor='white')\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# Plot 2: Subclusters with Main Cluster Color Coding\n",
    "# ============================================================================\n",
    "# Define main cluster colors\n",
    "main_cluster_colors = plt.cm.tab10(np.linspace(0, 1, 6))\n",
    "\n",
    "# Create custom colors for subclusters that inherit from main clusters\n",
    "for cluster_id in range(6):\n",
    "    cluster_mask = dataset_with_clusters['main_cluster'] == cluster_id\n",
    "    cluster_data = dataset_with_clusters[cluster_mask]\n",
    "    cluster_points = features_2d[cluster_mask]\n",
    "    \n",
    "    # Get unique subclusters in this main cluster\n",
    "    subclusters = sorted(cluster_data['subcluster'].unique())\n",
    "    n_subs = len(subclusters)\n",
    "    \n",
    "    # Create variations of the main cluster color for subclusters\n",
    "    if n_subs == 1:\n",
    "        # Single subcluster - use main color\n",
    "        axes[1].scatter(\n",
    "            cluster_points[:, 0],\n",
    "            cluster_points[:, 1],\n",
    "            c=[main_cluster_colors[cluster_id]],\n",
    "            alpha=0.6,\n",
    "            s=30,\n",
    "            edgecolors='black',\n",
    "            linewidth=0.5,\n",
    "            label=f'C{cluster_id}.0'\n",
    "        )\n",
    "    else:\n",
    "        # Multiple subclusters - use different shades\n",
    "        base_color = main_cluster_colors[cluster_id]\n",
    "        for i, sub_id in enumerate(subclusters):\n",
    "            sub_mask = cluster_data['subcluster'] == sub_id\n",
    "            sub_indices = cluster_data[sub_mask].index\n",
    "            sub_points = features_2d[sub_indices]\n",
    "            \n",
    "            # Vary brightness for subclusters\n",
    "            brightness = 0.5 + (i * 0.5 / (n_subs - 1))  # Range from 0.6 to 1.0\n",
    "            sub_color = base_color * brightness\n",
    "            sub_color[3] = 0.7  # Set alpha\n",
    "            \n",
    "            axes[1].scatter(\n",
    "                sub_points[:, 0],\n",
    "                sub_points[:, 1],\n",
    "                c=[sub_color],\n",
    "                alpha=0.6,\n",
    "                s=30,\n",
    "                edgecolors='black',\n",
    "                linewidth=0.5,\n",
    "                label=f'C{cluster_id}.{sub_id}'\n",
    "            )\n",
    "\n",
    "axes[1].set_title('Subclusters (Color-Coded by Main Cluster)', fontsize=16, fontweight='bold')\n",
    "axes[1].set_xlabel('T-SNE Component 1', fontsize=12)\n",
    "axes[1].set_ylabel('T-SNE Component 2', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add legend with compact layout\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8, ncol=2)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the figure explicitly\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Mood Recommendation System - Workflow\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    START[(\"\ud83c\udfb5 User's Spotify Library\n",
    "    13,079 songs\")]\n",
    "\n",
    "    subgraph PREP [\"Data Preprocessing\"]\n",
    "        CLEAN[\"Standardize & Clean\n",
    "        \u2022 Lowercase\n",
    "        \u2022 Deduplicate\"]\n",
    "        MATCH[\"Match with Global Dataset\n",
    "        \u2713 478 songs matched\"]\n",
    "        CLUSTER[\"Inherit Cluster Labels\n",
    "        \u2022 main_cluster\n",
    "        \u2022 subcluster\"]\n",
    "    end\n",
    "\n",
    "    START --> CLEAN\n",
    "    CLEAN --> MATCH\n",
    "    MATCH --> CLUSTER\n",
    "\n",
    "    PROFILE[(\"\u2705 User Profile Created\")]\n",
    "    CLUSTER --> PROFILE\n",
    "\n",
    "    subgraph APP [\"Recommendation App\"]\n",
    "        INPUT[\"\ud83d\udc64 User Input\n",
    "        Mood: Sad/Reflective\n",
    "        Songs: 20\"]\n",
    "\n",
    "        ANALYZE[\"\ud83d\udcca Analyze Distribution\n",
    "        Subcluster 0: 60 songs (73%)\n",
    "        Subcluster 1: 22 songs (27%)\"]\n",
    "\n",
    "        ALLOCATE[\"\u2696\ufe0f Proportional Allocation\n",
    "        Subcluster 0: 15 songs\n",
    "        Subcluster 1: 5 songs\"]\n",
    "    end\n",
    "\n",
    "    PROFILE --> INPUT\n",
    "    INPUT --> ANALYZE\n",
    "    ANALYZE --> ALLOCATE\n",
    "\n",
    "    subgraph ENGINE [\"Recommendation Engine\"]\n",
    "        FEATURES[\"Calculate User Profile\n",
    "        Average audio features:\n",
    "        \u2022 Danceability\n",
    "        \u2022 Energy\n",
    "        \u2022 Valence\n",
    "        \u2022 Acousticness\"]\n",
    "\n",
    "        CANDIDATES[\"\ud83d\udd0d Find Candidates\n",
    "        \u2713 Same mood cluster\n",
    "        \u2713 Same subcluster\n",
    "        \u2717 Exclude owned songs\"]\n",
    "\n",
    "        SIMILARITY[\"\ud83d\udcd0 Cosine Similarity\n",
    "        Rank by similarity to\n",
    "        user profile\"]\n",
    "    end\n",
    "\n",
    "    ALLOCATE --> FEATURES\n",
    "    FEATURES --> CANDIDATES\n",
    "    CANDIDATES --> SIMILARITY\n",
    "\n",
    "    OUTPUT[(\"\ud83c\udfa7 Final Recommendations\n",
    "    20 personalized songs\n",
    "    \u2713 Balanced across subclusters\n",
    "    \u2713 High similarity match\")]\n",
    "\n",
    "    SIMILARITY --> OUTPUT\n",
    "\n",
    "    style START fill:#1DB954,stroke:#191414,color:#fff\n",
    "    style PROFILE fill:#1DB954,stroke:#191414,color:#fff\n",
    "    style OUTPUT fill:#1DB954,stroke:#191414,color:#fff\n",
    "    style PREP fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style APP fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style ENGINE fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style CLEAN fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style MATCH fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style CLUSTER fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style INPUT fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style ANALYZE fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style ALLOCATE fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style FEATURES fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style CANDIDATES fill:#282828,stroke:#1DB954,color:#fff\n",
    "    style SIMILARITY fill:#282828,stroke:#1DB954,color:#fff\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MGSC661",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}