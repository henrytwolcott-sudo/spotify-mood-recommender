{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f31347f",
   "metadata": {},
   "source": [
    "# Spotify Dataset Cleaning\n",
    "\n",
    "This notebook cleans and preprocesses the Spotify dataset for music recommendation analysis.\n",
    "\n",
    "## Overview\n",
    "- Dataset: 114,000 Spotify tracks with audio features\n",
    "- Cleaning steps: missing values, duplicates, data validation, feature scaling\n",
    "- Output: Clean dataset ready for clustering and recommendation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fe180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165b87d",
   "metadata": {},
   "source": [
    "## **Upload files**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "print(f\"Shape: {df.shape[0]} rows \u00d7 {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc1853",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ca093",
   "metadata": {},
   "source": [
    "#### Data inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "print(\"Last 5 rows:\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data types of all columns:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "print(\"Dataset info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4effe620",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary statistics for numerical columns:\")\n",
    "display(df.describe())\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "print(\"Summary statistics (including non-numeric):\")\n",
    "display(df.describe(include='all'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fd181",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop irrelevant features\n",
    "print(df.columns.tolist())\n",
    "drop_cols = ['time_signature','key']\n",
    "df.drop(columns = drop_cols,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967034a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71b1a371",
   "metadata": {},
   "source": [
    "### Check for and handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "print(f\"\\nTotal missing values: {missing_values.sum()}\")\n",
    "df_clean = df.dropna()\n",
    "print(f\"\\nRows before: {len(df)}\")\n",
    "print(f\"Rows after: {len(df_clean)}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7458ae1a",
   "metadata": {},
   "source": [
    "### Split artyist names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05eb5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split on artist names\n",
    "# Split artists by semicolon\n",
    "artists_split = df_clean['artists'].str.split(';', expand=True)\n",
    "\n",
    "# Add the split columns to the dataframe with proper naming and cleaning\n",
    "for i in range(artists_split.shape[1]):\n",
    "    col_name = f'artist_{i+1}'\n",
    "    # Clean each artist column: strip whitespace and convert to lowercase\n",
    "    df_clean[col_name] = artists_split[i].str.strip().str.lower()\n",
    "\n",
    "df_clean.columns\n",
    "\n",
    "# # Only keep first 3 artists\n",
    "df_clean = df_clean[['track_id', 'album_name', 'track_name','duration_ms', 'explicit','popularity', 'danceability', 'energy', 'loudness', 'mode','speechiness', 'acousticness', 'instrumentalness', 'liveness','valence', 'tempo', 'track_genre', 'artist_1', 'artist_2', 'artist_3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd5edf",
   "metadata": {},
   "source": [
    "### Check for Duplicate Rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9fc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on track_name and artist_1\n",
    "df_clean_unique = df_clean.drop_duplicates(subset=['track_name', 'artist_1'], keep='first')\n",
    "\n",
    "print(f\"Original: {len(df_clean)} rows\")\n",
    "print(f\"Removed: {len(df_clean) - len(df_clean_unique)} duplicates\")\n",
    "print(f\"Final: {len(df_clean_unique)} rows\")\n",
    "df_clean=df_clean_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5721c0e0",
   "metadata": {},
   "source": [
    "### Data Type Conversion (if needed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting data types:\")\n",
    "#Converting explicit from boolean to binary\n",
    "if 'explicit' in df_clean.columns:\n",
    "    df_clean['explicit'] = df_clean['explicit'].astype(int)\n",
    "    print(\"\u2713 Converted 'explicit' to binary (0/1)\")\n",
    "\n",
    "unnamed_cols = [\n",
    "    col for col in df_clean.columns if 'Unnamed' in col or col == '']\n",
    "if unnamed_cols:\n",
    "    df_clean = df_clean.drop(columns=unnamed_cols)\n",
    "    print(f\"\u2713 Dropped unnamed index columns: {unnamed_cols}\")\n",
    "else:\n",
    "    print(\"\u2713 No unnamed columns to drop\")\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df_clean.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = [col for col in df_clean.columns if 'date' in col.lower()\n",
    "                or 'time' in col.lower()]\n",
    "if date_columns:\n",
    "    print(f\"Date columns found: {date_columns}\")\n",
    "else:\n",
    "    print(\"No date columns to parse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_candidates = df_clean.select_dtypes(\n",
    "    include=['object']).columns.tolist()\n",
    "print(\n",
    "    f\"Remaining object columns that could be categorical: {categorical_candidates}\")\n",
    "print(\n",
    "    f\"\\nCurrent categorical columns: {df_clean.select_dtypes(include=['category']).columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7587240",
   "metadata": {},
   "source": [
    "### Handle Inconsistent Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = df_clean.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Text columns to standardize: {text_columns}\")\n",
    "\n",
    "for col in text_columns:\n",
    "    df_clean[col] = df_clean[col].str.strip()\n",
    "    df_clean[col] = df_clean[col].str.lower()\n",
    "    print(f\"\u2713 Standardized '{col}': lowercase and stripped whitespace\")\n",
    "\n",
    "print(\"\\nSample of standardized data:\")\n",
    "display(df_clean[text_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b84afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'track_genre' in df_clean.columns:\n",
    "    print(\"Unique genres before cleaning:\")\n",
    "    print(f\"Total unique genres: {df_clean['track_genre'].nunique()}\")\n",
    "\n",
    "    print(\"\\nChecking for inconsistent values in track_genre...\")\n",
    "    genre_counts = df_clean['track_genre'].value_counts()\n",
    "    print(f\"\\nTop 10 genres:\")\n",
    "    print(genre_counts.head(10))\n",
    "else:\n",
    "    print(\"No track_genre column to check for inconsistencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb127bcb",
   "metadata": {},
   "source": [
    "### Validate Data Integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085cd4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking for logical inconsistencies:\\n\")\n",
    "\n",
    "if 'popularity' in df_clean.columns:\n",
    "    invalid_popularity = df_clean[(df_clean['popularity'] < 0) | (\n",
    "        df_clean['popularity'] > 100)]\n",
    "    print(\n",
    "        f\"  - Popularity out of range [0-100]: {len(invalid_popularity)} rows\")\n",
    "\n",
    "if 'duration_ms' in df_clean.columns:\n",
    "    invalid_duration = df_clean[df_clean['duration_ms'] < 90000]         #any track below 1 min 30 seconds \n",
    "    print(f\"  - Duration < 90000: {len(invalid_duration)} rows\")\n",
    "if 'duration_ms' in df_clean.columns:\n",
    "    invalid_duration = df_clean[df_clean['duration_ms'] > 900000]         #any track 15 minutes or longer\n",
    "    print(f\"  - Duration > 900000: {len(invalid_duration)} rows\")\n",
    "\n",
    "if 'tempo' in df_clean.columns:\n",
    "    invalid_tempo = df_clean[df_clean['tempo'] < 0]\n",
    "    print(f\"  - Tempo < 0: {len(invalid_tempo)} rows\")\n",
    "\n",
    "print(\"\\n\u2713 Logical consistency check complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d908159",
   "metadata": {},
   "source": [
    "### As you can see, 2846 tracks have a duration of less than 1 min 30 seconds\n",
    "### And 153 had a duration of longer than 15 mins\n",
    "### these will all be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923993bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tracks with duration < 90 seconds (90000 ms)\n",
    "df_clean = df_clean[df_clean['duration_ms'] >= 90000]\n",
    "df_clean = df_clean[df_clean['duration_ms'] <= 900000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64387b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verifying ranges and constraints:\\n\")\n",
    "\n",
    "audio_features = ['danceability', 'energy', 'speechiness', 'acousticness',\n",
    "                  'instrumentalness', 'liveness', 'valence']\n",
    "\n",
    "for feature in audio_features:\n",
    "    if feature in df_clean.columns:\n",
    "        out_of_range = df_clean[(df_clean[feature] < 0)\n",
    "                                | (df_clean[feature] > 1)]\n",
    "        print(f\"  - {feature} out of range [0-1]: {len(out_of_range)} rows\")\n",
    "\n",
    "\n",
    "if 'mode' in df_clean.columns:\n",
    "    invalid_mode = df_clean[(df_clean['mode'] < 0) | (df_clean['mode'] > 1)]\n",
    "    print(f\"  - Mode out of range [0-1]: {len(invalid_mode)} rows\")\n",
    "\n",
    "print(\"\\n\u2713 Range validation complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedda3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cross-checking related columns:\\n\")\n",
    "\n",
    "if 'loudness' in df_clean.columns:\n",
    "    print(\n",
    "        f\"  - Loudness range: [{df_clean['loudness'].min():.2f}, {df_clean['loudness'].max():.2f}] dB\")\n",
    "    print(f\"    Expected: typically between -60 and 0 dB\")\n",
    "\n",
    "if 'tempo' in df_clean.columns:\n",
    "    print(\n",
    "        f\"  - Tempo range: [{df_clean['tempo'].min():.2f}, {df_clean['tempo'].max():.2f}] BPM\")\n",
    "    print(f\"    Expected: typically between 50 and 200 BPM\")\n",
    "if 'duration_ms' in df_clean.columns:\n",
    "    duration_seconds = df_clean['duration_ms'] / 1000\n",
    "    print(\n",
    "        f\"  - Duration range: [{duration_seconds.min():.2f}, {duration_seconds.max():.2f}] seconds\")\n",
    "    print(\n",
    "        f\"    ({duration_seconds.min()/60:.2f} to {duration_seconds.max()/60:.2f} minutes)\")\n",
    "\n",
    "print(\"\\n\u2713 Cross-check complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27c11b",
   "metadata": {},
   "source": [
    "### There appear to be some tracks with loudness ratings above 0. These are higher than the system can handle and will distort, so we must remove these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3904b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['loudness'] <= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72209469",
   "metadata": {},
   "source": [
    "## Scale unscaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.describe()\n",
    "# From df_clean.describe it is clear that a few features are not scaled from the raw data:\n",
    "# These include loudness in which more negative values actually represent higher loudness, and tempo which is the opposite way arround\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import dump\n",
    "\n",
    "print(\"Creating and saving scalers:\\n\")\n",
    "\n",
    "# Tempo: Higher BPM = 1, Lower BPM = 0\n",
    "tempo_scaler = MinMaxScaler()\n",
    "df_clean['tempo_scaled'] = tempo_scaler.fit_transform(df_clean[['tempo']])\n",
    "print(f\"\u2713 Tempo: [{df_clean['tempo'].min():.0f}, {df_clean['tempo'].max():.0f}] BPM \u2192 [0, 1]\")\n",
    "\n",
    "# Loudness: Lower dB = 1, Higher dB = 0 (reversed)\n",
    "loudness_scaler = MinMaxScaler()\n",
    "df_clean['loudness_scaled'] = 1 - loudness_scaler.fit_transform(df_clean[['loudness']])\n",
    "print(f\"\u2713 Loudness: [{df_clean['loudness'].min():.1f}, {df_clean['loudness'].max():.1f}] dB \u2192 [0, 1] (reversed)\")\n",
    "\n",
    "# Save scalers\n",
    "dump(tempo_scaler, 'tempo_scaler.joblib')\n",
    "dump(loudness_scaler, 'loudness_scaler.joblib')\n",
    "print(\"\\n\u2713 Scalers saved to .joblib files\")\n",
    "\n",
    "df_clean.drop(columns=['tempo','loudness'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f5a8c",
   "metadata": {},
   "source": [
    "### Create Clean Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d82f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('dataset_cleaned.csv', index=False)\n",
    "print(\"\u2713 Cleaned dataset saved to: dataset_cleaned.csv\")\n",
    "print(f\"  Rows: {df_clean.shape[0]}\")\n",
    "print(f\"  Columns: {df_clean.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5c518",
   "metadata": {},
   "source": [
    "### Summary of cleaning process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e026e73",
   "metadata": {},
   "source": [
    "## Data Cleaning Summary\n",
    "\n",
    "### Initial Dataset\n",
    "- **114,000 rows \u00d7 21 columns**\n",
    "- Spotify track data with audio features and metadata\n",
    "\n",
    "### 1. Data Inspection\n",
    "- Examined first/last rows, data types, and shape\n",
    "- Generated summary statistics for all columns\n",
    "- Identified data structure and feature distributions\n",
    "\n",
    "### 2. Missing Values\n",
    "- **Found:** 3 missing values (1 each in artists, album_name, track_name)\n",
    "- **Action:** Filled missing text columns with mode values\n",
    "  - artists \u2192 \"The Beatles\"\n",
    "  - album_name \u2192 \"Alternative Christmas 2022\"\n",
    "  - track_name \u2192 \"Run Rudolph Run\"\n",
    "- **Result:** 0 missing values remaining\n",
    "\n",
    "### 3. Duplicate Rows\n",
    "- **Found:** 0 duplicate rows\n",
    "- **Action:** No removal needed\n",
    "\n",
    "### 4. Data Type Conversion\n",
    "- Converted `explicit` to boolean type\n",
    "- Dropped `Unnamed: 0` index column\n",
    "- Verified all other data types are appropriate\n",
    "\n",
    "### 5. Text Standardization\n",
    "- Standardized all text columns (track_id, artists, album_name, track_name, track_genre)\n",
    "- Applied lowercase transformation\n",
    "- Stripped leading/trailing whitespace\n",
    "- Verified genre consistency (114 unique genres, balanced distribution)\n",
    "\n",
    "### 6. Data Integrity Validation\n",
    "- **Popularity:** All values within valid range [0-100]\n",
    "- **Duration:** 1 row with duration \u2264 0 identified\n",
    "- **Tempo:** 157 rows with tempo \u2264 0 identified\n",
    "- **Audio features:** All within expected [0-1] range\n",
    "- **Loudness:** Range [-49.53, 4.53] dB (some positive values indicate clipping)\n",
    "- **Time signature:** 163 rows out of typical range [1-7]\n",
    "\n",
    "### Current Dataset Status\n",
    "- **114,000 rows \u00d7 20 columns** (after dropping Unnamed: 0)\n",
    "- **Columns:** track_id, artists, album_name, track_name, track_genre, popularity, duration_ms, explicit, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, time_signature\n",
    "- **Output:** Saved to `dataset_cleaned.csv`\n",
    "\n",
    "### Next Steps\n",
    "- Remove invalid rows (duration \u2264 0, tempo \u2264 0, loudness > 0)\n",
    "- Separate metadata columns from feature columns\n",
    "- Drop irrelevant features (key, mode, time_signature)\n",
    "- Scale features for clustering analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MGSC661",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}